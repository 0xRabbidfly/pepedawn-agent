OPENAI_API_KEY=
PGLITE_DATA_DIR=
TELEGRAM_BOT_TOKEN= #fetch from TG
TELEGRAM_ADMIN_IDS= #fetch from TG
SUPPRESS_BOOTSTRAP=false
# ============================================
# KNOWLEDGE PLUGIN - OPTIMIZED SETTINGS
# ============================================

# DISABLE CTX enrichment - saves time and money for chat messages
CTX_KNOWLEDGE_ENABLED=false

# Knowledge path
KNOWLEDGE_PATH=./docs/chunks

# Load docs on startup
LOAD_DOCS_ON_STARTUP=false

# ============================================
# EMBEDDING SETTINGS - COST OPTIMIZED
# ============================================

# Provider
EMBEDDING_PROVIDER=openai

# Use text-embedding-3-small (6.5x cheaper than large)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
TEXT_EMBEDDING_MODEL=text-embedding-3-small

# Dimensions (1536 for small model)
EMBEDDING_DIMENSION=1536
OPENAI_EMBEDDING_DIMENSIONS=1536

# ============================================
# LLM SETTINGS
# ============================================

# Text provider and model for bot responses
OPENAI_SMALL_MODEL=gpt-4o-mini        # Default: gpt-4o-mini
OPENAI_LARGE_MODEL=gpt-4o             # Default: gpt-4o

# TEXT_PROVIDER=openai
# TEXT_MODEL=gpt-4o

# ============================================
# RATE LIMITS - OPTIMIZED FOR FAST PROCESSING
# ============================================

# Token constraints
MAX_INPUT_TOKENS=4000
MAX_OUTPUT_TOKENS=4096

# Default recommended values from plugin-knowledge
MAX_CONCURRENT_REQUESTS=30
REQUESTS_PER_MINUTE=60      
TOKENS_PER_MINUTE=150000
